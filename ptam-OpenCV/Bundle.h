// George Terzakis 2016
//
// University of Portsmouth
//
// Code based on original PTAM code by Klein and Murray (Copyright 2008 Isis Innovation Limited)

#ifndef __BUNDLE_H
#define __BUNDLE_H
// Bundle.h
// 
// This file declares the Bundle class along with a few helper classes.
// Bundle is the bundle adjustment core of the mapping system; instances
// of Bundle are generated by MapMaker to adjust the positions of 
// keyframes (called Cameras in this file) and map points.
//
// It's a pretty straight-forward Levenberg-Marquardt bundle adjustment 
// implementation closely following Hartley and Zisserman's MVG book, with
// the addition of a robust M-Estimator.
//
// Unfortunately, having undergone a few tweaks, the code is now
// not the easiest to read!
//
// Basic operation: MapMaker creates a new Bundle object;
// then adds map points and keyframes to adjust;
// then adds measurements of map points in keyframes;
// then calls Compute() to do bundle adjustment;
// then reads results back to update the map.

#include "ATANCamera.h"

#include "GCVD/SE3.h"

#include <vector>
#include <map>
#include <set>
#include <list>

using namespace RigidTransforms;

// An index into the big measurement map which stores all the measurements.

// Camera struct holds the pose of a keyframe
// and some computation intermediates
struct BACamera
{
  bool bFixed;
  SE3<> se3CfW;
  SE3<> se3CfWNew;
  cv::Matx<float, 6, 6> m6U;          // 6x6 Accumulator
  cv::Vec<float, 6> v6EpsilonA;   // 6x1 Accumulator
  int nStartRow;
};

// Camera-camera pair index
// This struct represents a correlation between
// camera views through measurements (i.e., commonly visible points)
struct OffDiagScriptEntry
{
  //int j;
  int cam1Index;
  //int k;
  int cam2Index;
};

// A map point, plus computation intermediates.
struct BAPoint
{
  inline BAPoint() { 
    
    nMeasurements = 0; 
    nOutliers = 0;
    
  }
  cv::Vec<float, 3> v3Pos;
  cv::Vec<float, 3> v3PosNew;
  cv::Matx<float, 3, 3> m3V;          // 3x3 Accumulator
  cv::Vec<float, 3> v3EpsilonB;         // 3x1 Accumulator 
  cv::Matx<float, 3, 3> m3VStarInv;   // 3x3 
  
  int nMeasurements;
  int nOutliers;
  std::set<int> sCameras; // Which cameras observe this point?
  std::vector<OffDiagScriptEntry> vOffDiagonalScript; // A record of all camera-camera pairs observing this point
};

// A measurement of a point by a camera, plus
// computation intermediates.
struct BAMeasurement
{
  inline BAMeasurement() { bBad = false;}
  
  // Which camera/point did this measurement come from?
  int pointIndex; // The point  - called i in MVG
  int camIndex; // The camera - called j in MVG

  inline bool operator <(const BAMeasurement &rhs) const {  
    return(camIndex < rhs.camIndex || (camIndex == rhs.camIndex && pointIndex < rhs.pointIndex)); 
    
  }
  
  bool bBad;
  
  cv::Vec<float, 2> v2Found;
  cv::Vec<float, 2> v2Epsilon;
  cv::Matx<float, 2, 6> m26A; // 2x6
  cv::Matx<float, 2, 3> m23B; // 2x3
  cv::Matx<float, 6, 3> m63W; // 6x3
  //cv::Matx<float, 6, 3> m63Y; // 6x3 // NOT IN USE. And is not really necessary (although it is defined in A6.4)
  
  double dSqrtInvNoise;
  
  // Temporary projection quantities
  cv::Vec<float, 3> v3Cam;
  double dErrorSquared;
  cv::Matx<float, 2, 2> m2CamDerivs; // 2x2
};

// Core bundle adjustment class
class Bundle
{
public:

  Bundle(const ATANCamera &TCam);   // We need the camera model because we do full distorting projection in the bundle adjuster. Could probably get away with a linear approximation.
  int AddCamera(SE3<> se3CamFromWorld, bool bFixed); // Add a viewpoint. bFixed signifies that this one is not to be adjusted.
  int AddPoint(cv::Vec<float, 3> v3Pos);       // Add a map point.
  void AddMeasurement(int nCam, int nPoint, cv::Vec<float, 2> v2Pos, double dSigmaSquared); // Add a measurement
  int Compute(bool *pbAbortSignal);    // Perform bundle adjustment. Aborts if *pbAbortSignal gets set to true. Returns number of accepted update iterations, or negative on error.
  inline bool Converged() { return mbConverged;}  // Has bundle adjustment converged?
  cv::Vec<float, 3> GetPointCoords(int n);       // Point coords after adjustment
  SE3<> GetCameraPose(int n);            // Camera pose after adjustment
  std::vector<std::pair<int,int> > GetOutlierMeasurements();  // Measurements flagged as outliers
  std::set<int> GetOutliers();                                // Points flagged as outliers
  
protected:

  inline void ProjectAndFindSquaredError(BAMeasurement &measurement); // Project a single point in a single view, compare to measurement
  template<class MEstimator> bool Do_LM_Step(bool *pbAbortSignal);
  template<class MEstimator> double FindNewError();
  void GenerateMeasurementLUTs();
  void GenerateOffDiagScripts();
  void ClearAccumulators(); // Zero temporary quantities stored in cameras and points
  void ModifyLambda_GoodStep();
  void ModifyLambda_BadStep();
  
  std::vector<BAPoint> mvPoints;
  std::vector<BACamera> mvCameras;
  std::list<BAMeasurement> mMeasList;
  std::vector<std::pair<int,int> > mvOutlierMeasurementIdx;  // p-c pair
  std::vector<std::vector<BAMeasurement*> > mvMeasLUTs;  //Each camera gets a per-point table of pointers to valid measurements
  
  ATANCamera mCamera;
  int mnCamsToUpdate;
  int mnStartRow;
  double mdSigmaSquared;
  double mdLambda;
  double mdLambdaFactor;
  bool mbConverged;
  bool mbHitMaxIterations;
  int mnCounter;
  int mnAccepted;
  
  Persistence::pvar3<int> mgvnMaxIterations;
  Persistence::pvar3<double> mgvdUpdateConvergenceLimit;
  Persistence::pvar3<int> mgvnBundleCout;
  
  bool *mpbAbortSignal;
};





#endif
